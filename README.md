# üéµ Syst√®me de Classification Audio avec TensorFlow

Ce projet impl√©mente un syst√®me de classification audio utilisant des r√©seaux de neurones profonds pour identifier diff√©rentes classes de sons dans des fichiers audio.

## üìã Table des Mati√®res

- [Description](#description)
- [Installation](#installation)
- [Structure du Projet](#structure-du-projet)
- [Utilisation](#utilisation)
- [Ajout de Nouvelles Donn√©es](#ajout-de-nouvelles-donn√©es)
- [Param√®tres du Mod√®le](#param√®tres-du-mod√®le)
- [Format des Donn√©es](#format-des-donn√©es)
- [Scripts Disponibles](#scripts-disponibles)
- [D√©pannage](#d√©pannage)

---

## üìñ Description

Ce syst√®me permet de :
- **Entra√Æner** un mod√®le de classification audio sur des segments audio √©tiquet√©s
- **Pr√©dire** la classe d'un fichier audio ou d'un segment
- **Analyser** des fichiers audio complets (plusieurs heures) en les segmentant automatiquement
- **Visualiser** les r√©sultats sous forme de graphiques et de fichiers CSV

Le mod√®le utilise des caract√©ristiques audio avanc√©es (mel-spectrogramme, MFCC, chroma, etc.) et une architecture de r√©seau de neurones avec r√©gularisation pour √©viter le surapprentissage.

---

## üîß Installation

### Pr√©requis

- Python 3.8 ou sup√©rieur
- pip (gestionnaire de paquets Python)

### Installation des D√©pendances

```bash
# Cr√©er un environnement virtuel (recommand√©)
python3 -m venv venv

# Activer l'environnement virtuel
# Sur Linux/Mac:
source venv/bin/activate
# Sur Windows:
# venv\Scripts\activate

# Installer les d√©pendances
pip install tensorflow librosa soundfile pandas numpy scikit-learn matplotlib
```

### D√©pendances Principales

- **tensorflow** : Framework de deep learning
- **librosa** : Traitement et analyse audio
- **soundfile** : Lecture/√©criture de fichiers audio
- **pandas** : Manipulation de donn√©es
- **numpy** : Calculs num√©riques
- **scikit-learn** : Outils de machine learning
- **matplotlib** : Visualisation

---

## üìÅ Structure du Projet

```
TensorFlow_Test/
‚îú‚îÄ‚îÄ slices/                    # Dossier contenant les segments audio d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ slice_001.wav
‚îÇ   ‚îú‚îÄ‚îÄ slice_002.wav
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ annotation.csv             # Fichier d'annotations (labels des segments)
‚îú‚îÄ‚îÄ model_improved.py          # Script d'entra√Ænement du mod√®le am√©lior√©
‚îú‚îÄ‚îÄ model_improved.h5          # Mod√®le entra√Æn√© sauvegard√©
‚îú‚îÄ‚îÄ model_improved_best.h5     # Meilleur mod√®le (selon validation)
‚îú‚îÄ‚îÄ scaler.pkl                 # Scaler pour normaliser les nouvelles donn√©es
‚îú‚îÄ‚îÄ predict_improved.py        # Script de pr√©diction pour un fichier
‚îú‚îÄ‚îÄ predict_full_audio.py      # Script d'analyse d'un fichier audio complet
‚îú‚îÄ‚îÄ slicing.py                 # Script pour d√©couper un fichier audio en segments
‚îú‚îÄ‚îÄ annotation.py              # Script pour cr√©er le fichier d'annotations
‚îî‚îÄ‚îÄ README.md                  # Ce fichier
```

---

## üöÄ Utilisation

### 1. Entra√Æner le Mod√®le

Pour entra√Æner le mod√®le am√©lior√© avec vos donn√©es :

```bash
python model_improved.py
```

**Ce que fait le script :**
- Extrait les caract√©ristiques audio de tous les fichiers dans `slices/`
- Normalise les donn√©es
- Augmente les donn√©es (ajout de bruit, time stretching, pitch shifting)
- Entra√Æne le mod√®le avec validation
- Sauvegarde le mod√®le dans `model_improved.h5`
- Sauvegarde le scaler dans `scaler.pkl`
- G√©n√®re des graphiques d'√©volution dans `training_history_improved.png`

**Fichiers g√©n√©r√©s :**
- `model_improved.h5` : Mod√®le final
- `model_improved_best.h5` : Meilleur mod√®le (selon validation loss)
- `scaler.pkl` : Normaliseur pour les nouvelles pr√©dictions
- `training_history_improved.png` : Graphiques d'√©volution

### 2. Faire une Pr√©diction sur un Fichier

Pour pr√©dire la classe d'un fichier audio :

```bash
python predict_improved.py [chemin_vers_fichier_audio]
```

**Exemple :**
```bash
python predict_improved.py slices/slice_001.wav
```

**Sans argument**, le script utilise le premier fichier `.wav` trouv√© dans `slices/`.

### 3. Analyser un Fichier Audio Complet

Pour analyser un fichier audio long (plusieurs heures) :

```bash
python predict_full_audio.py [chemin_vers_fichier_audio]
```

**Param√®tres configurables** (dans le script, lignes 273-276) :
- `segment_duration` : Dur√©e de chaque segment en secondes (d√©faut: 30)
- `overlap` : Chevauchement entre segments en secondes (d√©faut: 5)
- `min_confidence` : Confiance minimale pour inclure une pr√©diction (d√©faut: 50%)
- `output_csv` : Nom du fichier CSV de sortie (d√©faut: "predictions_raw.csv")

**Exemple :**
```bash
python predict_full_audio.py mon_fichier_audio.wav
```

Le script g√©n√®re un fichier CSV (`predictions_raw.csv`) avec les pr√©dictions pour chaque segment.

---

## üì• Ajout de Nouvelles Donn√©es

### M√©thode 1 : Ajout Manuel de Segments

#### √âtape 1 : Pr√©parer les Fichiers Audio

1. **D√©couper votre fichier audio en segments** (si n√©cessaire) :
   ```bash
   python slicing.py [fichier_audio] [fichier_annotations]
   ```

   Le script `slicing.py` d√©coupe un fichier audio en segments bas√©s sur les annotations dans un fichier CSV.

2. **Placer les segments dans le dossier `slices/`** :
   - Format : fichiers `.wav`
   - Nommage : `slice_XXX.wav` (ex: `slice_028.wav`, `slice_029.wav`, etc.)

#### √âtape 2 : Cr√©er/Mettre √† Jour le Fichier d'Annotations

Le fichier `annotation.csv` doit avoir le format suivant :

```csv
nfile,length,label,reliability
slice_001.wav,38,1,3
slice_002.wav,13,2,3
slice_028.wav,25,1,3
slice_029.wav,30,2,2
```

**Colonnes :**
- `nfile` : Nom du fichier (doit correspondre au fichier dans `slices/`)
- `length` : Dur√©e du segment en secondes
- `label` : Classe/label du segment (entier, ex: 1, 2, 3, 4)
- `reliability` : Fiabilit√© de l'annotation (1-3, o√π 3 = tr√®s fiable)

**Exemple de cr√©ation/mise √† jour :**

Vous pouvez √©diter `annotation.csv` manuellement ou utiliser un script Python :

```python
import pandas as pd

# Lire le fichier existant
df = pd.read_csv('annotation.csv')

# Ajouter de nouvelles lignes
new_data = {
    'nfile': ['slice_028.wav', 'slice_029.wav'],
    'length': [25, 30],
    'label': [1, 2],
    'reliability': [3, 3]
}
df_new = pd.DataFrame(new_data)

# Concat√©ner avec les donn√©es existantes
df = pd.concat([df, df_new], ignore_index=True)

# Sauvegarder
df.to_csv('annotation.csv', index=False)
```

#### √âtape 3 : R√©entra√Æner le Mod√®le

Une fois les nouvelles donn√©es ajout√©es :

```bash
python model_improved.py
```

Le mod√®le sera r√©entra√Æn√© avec toutes les donn√©es (anciennes + nouvelles).

### M√©thode 2 : Utiliser le Script d'Annotation

Le script `annotation.py` peut √™tre utilis√© pour cr√©er le fichier d'annotations √† partir de donn√©es brutes. Consultez le fichier pour voir comment l'utiliser.

---

## ‚öôÔ∏è Param√®tres du Mod√®le

### Extraction de Caract√©ristiques

Le mod√®le extrait **304 caract√©ristiques** par fichier audio :

| Caract√©ristique | Nombre | Description |
|----------------|--------|-------------|
| **Mel-spectrogramme** | 256 | Moyenne (128) + √âcart-type (128) |
| **MFCC** | 26 | 13 coefficients avec moyenne et √©cart-type |
| **Chroma** | 12 | Caract√©ristiques harmoniques |
| **Spectral Contrast** | 7 | Contraste spectral |
| **Zero Crossing Rate** | 2 | Moyenne et √©cart-type |
| **Tempo** | 1 | Estimation du tempo (BPM) |
| **TOTAL** | **304** | |

**Param√®tres d'extraction :**
- Sample rate : 22050 Hz
- Mel bands : 128
- MFCC coefficients : 13

### Architecture du Mod√®le

```
Input (304 features)
  ‚Üì
Dense(512) + BatchNormalization + Dropout(0.5)
  ‚Üì
Dense(256) + BatchNormalization + Dropout(0.4)
  ‚Üì
Dense(128) + BatchNormalization + Dropout(0.3)
  ‚Üì
Dense(64) + BatchNormalization + Dropout(0.2)
  ‚Üì
Output (num_classes) + Softmax
```

**Hyperparam√®tres :**
- **Optimiseur** : Adam
- **Learning rate** : 0.0001 (avec decay)
- **Loss function** : Categorical crossentropy
- **Batch size** : 16
- **Epochs** : 200 (avec early stopping)
- **Early stopping patience** : 20 epochs
- **Reduce LR patience** : 10 epochs

### Augmentation de Donn√©es

Pour chaque √©chantillon d'entra√Ænement, le mod√®le cr√©e plusieurs versions augment√©es :
- **Bruit gaussien** : Ajout de bruit l√©ger (œÉ=0.005)
- **Time stretching** : Ralentissement (rate=0.9) et acc√©l√©ration (rate=1.1)
- **Pitch shifting** : Modification de la hauteur tonale (¬±2 demi-tons)

### Normalisation

- **StandardScaler** : Normalisation z-score (moyenne=0, √©cart-type=1)
- Le scaler est sauvegard√© dans `scaler.pkl` pour √™tre r√©utilis√© lors des pr√©dictions

---

## üìä Format des Donn√©es

### Fichier d'Annotations (`annotation.csv`)

```csv
nfile,length,label,reliability
slice_001.wav,38,1,3
slice_002.wav,13,2,3
```

**Labels :**
- Les labels sont des entiers (1, 2, 3, 4, etc.)
- Le nombre de classes est d√©termin√© automatiquement
- **Important** : Chaque classe doit avoir au moins 2 √©chantillons pour permettre la stratification

**Reliability :**
- 1 : Faible fiabilit√©
- 2 : Fiabilit√© moyenne
- 3 : Haute fiabilit√©

### Fichier Audio

**Format support√© :**
- `.wav` (recommand√©)
- `.mp3`, `.flac`, `.m4a`, `.ogg`, `.aac` (via librosa)

**Recommandations :**
- Dur√©e des segments : 10-60 secondes (optimal : 20-40 secondes)
- Sample rate : Toute valeur (sera convertie √† 22050 Hz)
- Canaux : Mono ou st√©r√©o (sera converti en mono)

### Fichier de Pr√©dictions (`predictions_raw.csv`)

Format g√©n√©r√© par `predict_full_audio.py` :

```csv
Start,End,Label,Reliability
00:03:20,00:03:50,4,1
00:09:35,00:10:05,4,1
```

**Colonnes :**
- `Start` : Timestamp de d√©but (HH:MM:SS)
- `End` : Timestamp de fin (HH:MM:SS)
- `Label` : Classe pr√©dite
- `Reliability` : 1 (‚â•50%), 2 (‚â•60%), 3 (‚â•80% confiance)

---

## üìú Scripts Disponibles

### `model_improved.py`
**Entra√Ænement du mod√®le am√©lior√©**
- Extrait les caract√©ristiques
- Normalise les donn√©es
- Augmente les donn√©es
- Entra√Æne le mod√®le
- Sauvegarde le mod√®le et le scaler

### `predict_improved.py`
**Pr√©diction sur un fichier audio**
- Charge le mod√®le et le scaler
- Extrait les caract√©ristiques
- Fait la pr√©diction
- Affiche les r√©sultats

### `predict_full_audio.py`
**Analyse d'un fichier audio complet**
- D√©coupe le fichier en segments
- Pr√©dit chaque segment
- Fusionne les segments cons√©cutifs
- G√©n√®re un CSV avec les r√©sultats

### `slicing.py`
**D√©coupage d'un fichier audio**
- D√©coupe un fichier audio en segments bas√©s sur des annotations
- G√©n√®re les fichiers dans `slices/`

### `annotation.py`
**Cr√©ation du fichier d'annotations**
- Convertit des donn√©es brutes en format CSV

---

## üîç D√©pannage

### Erreur : "No librosa.feature attribute chroma"
**Solution :** Le script d√©tecte automatiquement les fonctions disponibles. Si chroma n'est pas disponible, des z√©ros seront utilis√©s √† la place.

### Erreur : "The least populated class has only 1 member"
**Solution :** Chaque classe doit avoir au moins 2 √©chantillons. Ajoutez plus de donn√©es pour les classes minoritaires.

### Erreur : "File not found"
**Solution :** V√©rifiez que :
- Les fichiers audio sont dans le dossier `slices/`
- Les noms dans `annotation.csv` correspondent exactement aux noms des fichiers
- Les chemins sont corrects

### Performance Faible
**Solutions possibles :**
1. **Ajouter plus de donn√©es** : Le mod√®le a besoin d'au moins 50-100 √©chantillons par classe pour de bonnes performances
2. **√âquilibrer les classes** : Les classes d√©s√©quilibr√©es peuvent causer des probl√®mes
3. **V√©rifier la qualit√© des annotations** : Des annotations incorrectes d√©gradent les performances
4. **Ajuster les hyperparam√®tres** : Modifier le learning rate, batch size, etc.

### Mod√®le qui Surapprend
**Le mod√®le inclut d√©j√† :**
- Dropout (0.2-0.5)
- BatchNormalization
- Early stopping
- Augmentation de donn√©es

**Si le surapprentissage persiste :**
- Ajoutez plus de donn√©es
- Augmentez le dropout
- R√©duisez la taille du mod√®le

---

## üìà Am√©liorations Futures

- [ ] Support pour les architectures CNN 2D (spectrogrammes complets)
- [ ] Support pour LSTM/BiLSTM (d√©pendances temporelles)
- [ ] Transfer learning avec mod√®les pr√©-entra√Æn√©s
- [ ] Interface web pour l'annotation
- [ ] Validation crois√©e k-fold
- [ ] Recherche d'hyperparam√®tres automatis√©e
- [ ] Support pour l'apprentissage continu (fine-tuning)

---

## üìù Notes Importantes

1. **Donn√©es limit√©es** : Avec seulement 27-29 √©chantillons, les performances seront limit√©es. Collectez plus de donn√©es pour de meilleurs r√©sultats.

2. **Classes d√©s√©quilibr√©es** : Si certaines classes ont beaucoup plus d'√©chantillons que d'autres, le mod√®le peut √™tre biais√©. Essayez d'√©quilibrer les classes.

3. **Qualit√© des annotations** : La qualit√© du mod√®le d√©pend directement de la qualit√© des annotations. V√©rifiez que les labels sont corrects.

4. **Normalisation** : Le scaler (`scaler.pkl`) doit √™tre utilis√© avec le m√™me mod√®le. Si vous r√©entra√Ænez le mod√®le, r√©g√©n√©rez le scaler.

5. **Compatibilit√©** : Le mod√®le sauvegard√© (`model_improved.h5`) est compatible avec TensorFlow 2.x.

---

## üìß Support

Pour toute question ou probl√®me, consultez :
- Le fichier `AMELIORATIONS.md` pour les d√©tails techniques des am√©liorations
- Les commentaires dans les scripts Python
- La documentation TensorFlow : https://www.tensorflow.org/
- La documentation librosa : https://librosa.org/

---

**Derni√®re mise √† jour :** D√©cembre 2025
