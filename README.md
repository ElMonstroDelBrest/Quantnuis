# üéµ Syst√®me de Classification Audio avec TensorFlow

Ce projet impl√©mente un syst√®me de classification audio utilisant des r√©seaux de neurones profonds pour identifier diff√©rentes classes de sons dans des fichiers audio.

## üìã Table des Mati√®res

- [Description](#description)
- [Installation](#installation)
- [Structure du Projet](#structure-du-projet)
- [Utilisation](#utilisation)
- [Ajout de Nouvelles Donn√©es](#ajout-de-nouvelles-donn√©es)
- [Param√®tres du Mod√®le](#param√®tres-du-mod√®le)
- [Format des Donn√©es](#format-des-donn√©es)
- [Scripts Disponibles](#scripts-disponibles)
- [D√©pannage](#d√©pannage)

---

## üìñ Description

Ce syst√®me permet de :
- **Entra√Æner** un mod√®le de classification audio sur des segments audio √©tiquet√©s
- **Pr√©dire** la classe d'un fichier audio ou d'un segment
- **Analyser** des fichiers audio complets (plusieurs heures) en les segmentant automatiquement
- **Visualiser** les r√©sultats sous forme de graphiques et de fichiers CSV

Le mod√®le utilise des caract√©ristiques audio avanc√©es (mel-spectrogramme, MFCC, chroma, etc.) et une architecture de r√©seau de neurones avec r√©gularisation pour √©viter le surapprentissage.

---

## üîß Installation

### Pr√©requis

- Python 3.8 ou sup√©rieur
- pip (gestionnaire de paquets Python)

### Installation des D√©pendances

```bash
# Cr√©er un environnement virtuel (recommand√©)
python3 -m venv venv

# Activer l'environnement virtuel
# Sur Linux/Mac:
source venv/bin/activate
# Sur Windows:
# venv\Scripts\activate

# Installer les d√©pendances de base
pip install librosa soundfile pandas numpy scikit-learn matplotlib

# Installer TensorFlow (choisir selon votre configuration)
# Pour CPU uniquement:
pip install tensorflow

# Pour GPU NVIDIA (recommand√© si vous avez un GPU):
pip install tensorflow[and-cuda]

# V√©rifier la configuration GPU:
python test_gpu.py
```

> **üìñ Guide GPU :** Consultez `SETUP_GPU.md` pour la configuration d√©taill√©e du GPU NVIDIA.

### D√©pendances Principales

- **tensorflow** : Framework de deep learning
- **librosa** : Traitement et analyse audio
- **soundfile** : Lecture/√©criture de fichiers audio
- **pandas** : Manipulation de donn√©es
- **numpy** : Calculs num√©riques
- **scikit-learn** : Outils de machine learning
- **matplotlib** : Visualisation

---

## üìÅ Structure du Projet

```
Quantnuis-1/
‚îú‚îÄ‚îÄ data/                      # Dossier contenant toutes les donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ raw/                   # Fichiers CSV bruts d'annotations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ annotations_raw.csv
‚îÇ   ‚îú‚îÄ‚îÄ slices/                # Segments audio d'entra√Ænement
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ slice_001.wav
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ slice_002.wav
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ annotation.csv         # Fichier d'annotations principal (labels des segments)
‚îú‚îÄ‚îÄ models/                    # Mod√®les entra√Æn√©s et scalers
‚îÇ   ‚îú‚îÄ‚îÄ model_improved.h5      # Mod√®le entra√Æn√© sauvegard√©
‚îÇ   ‚îú‚îÄ‚îÄ model_improved_best.h5 # Meilleur mod√®le (selon validation)
‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl             # Scaler pour normaliser les nouvelles donn√©es
‚îú‚îÄ‚îÄ output/                    # R√©sultats et pr√©dictions
‚îÇ   ‚îú‚îÄ‚îÄ predictions_raw.csv    # Pr√©dictions g√©n√©r√©es
‚îÇ   ‚îî‚îÄ‚îÄ training_history_improved.png
‚îú‚îÄ‚îÄ main.py                    # Script principal (menu interactif)
‚îú‚îÄ‚îÄ annotation.py              # Script pour cr√©er le fichier d'annotations
‚îú‚îÄ‚îÄ slicing.py                 # Script pour d√©couper un fichier audio en segments
‚îú‚îÄ‚îÄ model_improved.py          # Script d'entra√Ænement du mod√®le am√©lior√©
‚îú‚îÄ‚îÄ predict_improved.py        # Script de pr√©diction pour un fichier
‚îú‚îÄ‚îÄ predict_full_audio.py      # Script d'analyse d'un fichier audio complet
‚îî‚îÄ‚îÄ README.md                  # Ce fichier
```

---

## üöÄ Utilisation

### M√©thode Simple : Script Principal

Le moyen le plus simple de lancer les diff√©rentes √©tapes est d'utiliser le script principal :

```bash
python main.py
```

Cela affiche un menu interactif avec toutes les options disponibles.

Vous pouvez aussi lancer directement une action :

```bash
python main.py 1  # Cr√©er les annotations
python main.py 2  # D√©couper un fichier audio
python main.py 3  # Entra√Æner le mod√®le
python main.py 4  # Pr√©dire sur un fichier
python main.py 5  # Analyser un fichier complet
```

### M√©thode Avanc√©e : Scripts Individuels

#### 1. Cr√©er le Fichier d'Annotations

```bash
python annotation.py
```

G√©n√®re `data/raw/annotations_raw.csv` √† partir des donn√©es brutes dans le script.

#### 2. D√©couper un Fichier Audio

```bash
python slicing.py [chemin_vers_fichier_audio]
```

**Ce que fait le script :**
- Lit les annotations depuis `data/raw/annotations_raw.csv` (ou le plus r√©cent fichier `*_annotations_raw.csv`)
- D√©coupe le fichier audio en segments selon les timestamps
- Sauvegarde les segments dans `data/slices/`
- Cr√©e `data/annotation.csv` avec les m√©tadonn√©es

**Sans argument**, le script cherche automatiquement un fichier audio dans le r√©pertoire courant.

#### 3. Entra√Æner le Mod√®le

```bash
python model_improved.py
```

**Ce que fait le script :**
- Extrait les caract√©ristiques audio de tous les fichiers dans `data/slices/`
- Normalise les donn√©es
- Augmente les donn√©es (ajout de bruit, time stretching, pitch shifting)
- Entra√Æne le mod√®le avec validation
- Sauvegarde le mod√®le dans `models/model_improved.h5`
- Sauvegarde le scaler dans `models/scaler.pkl`
- G√©n√®re des graphiques dans `output/training_history_improved.png`

**Fichiers g√©n√©r√©s :**
- `models/model_improved.h5` : Mod√®le final
- `models/model_improved_best.h5` : Meilleur mod√®le (selon validation loss)
- `models/scaler.pkl` : Normaliseur pour les nouvelles pr√©dictions
- `output/training_history_improved.png` : Graphiques d'√©volution

#### 4. Faire une Pr√©diction sur un Fichier

```bash
python predict_improved.py [chemin_vers_fichier_audio]
```

**Exemple :**
```bash
python predict_improved.py data/slices/slice_001.wav
```

**Sans argument**, le script utilise le premier fichier `.wav` trouv√© dans `data/slices/`.

#### 5. Analyser un Fichier Audio Complet

```bash
python predict_full_audio.py [chemin_vers_fichier_audio]
```

**Param√®tres configurables** (dans le script) :
- `segment_duration` : Dur√©e de chaque segment en secondes (d√©faut: 30)
- `overlap` : Chevauchement entre segments en secondes (d√©faut: 5)
- `min_confidence` : Confiance minimale pour inclure une pr√©diction (d√©faut: 50%)

**Exemple :**
```bash
python predict_full_audio.py mon_fichier_audio.wav
```

Le script g√©n√®re un fichier CSV (`output/predictions_raw.csv`) avec les pr√©dictions pour chaque segment.

---

## üì• Ajout de Nouvelles Donn√©es

> **üìñ Guide d√©taill√© :** Consultez `AJOUT_DONNEES.md` pour un guide complet √©tape par √©tape.

### Workflow Rapide

1. **Pr√©parer le CSV d'annotations** : Placez votre fichier CSV dans `data/raw/` avec le format :
   ```csv
   Start,End,Label,Reliability
   00:09:34,00:10:12,1,3
   ```

2. **D√©couper l'audio** : 
   ```bash
   python main.py 2
   # Entrez le chemin vers votre fichier audio
   ```
   Les nouveaux slices seront **automatiquement ajout√©s** √† `data/slices/` et les annotations √† `data/annotation.csv` (sans doublons).

3. **R√©entra√Æner le mod√®le** (optionnel) :
   ```bash
   python main.py 3
   ```

### M√©thode 1 : Ajout Manuel de Segments

#### √âtape 1 : Cr√©er les Annotations Brutes

1. **Cr√©er le fichier d'annotations brutes** :
   ```bash
   python annotation.py
   ```
   
   Cela g√©n√®re `data/raw/annotations_raw.csv` avec les timestamps et labels.

#### √âtape 2 : D√©couper le Fichier Audio

1. **D√©couper votre fichier audio en segments** :
   ```bash
   python slicing.py [fichier_audio]
   ```

   Le script `slicing.py` :
   - Lit automatiquement `data/raw/annotations_raw.csv` (ou le plus r√©cent)
   - D√©coupe le fichier audio en segments bas√©s sur les annotations
   - Sauvegarde les segments dans `data/slices/`
   - Cr√©e `data/annotation.csv` avec les m√©tadonn√©es

#### √âtape 3 : V√©rifier le Fichier d'Annotations

Le fichier `data/annotation.csv` doit avoir le format suivant :

```csv
nfile,length,label,reliability
slice_001.wav,38,1,3
slice_002.wav,13,2,3
slice_028.wav,25,1,3
slice_029.wav,30,2,2
```

**Colonnes :**
- `nfile` : Nom du fichier (doit correspondre au fichier dans `slices/`)
- `length` : Dur√©e du segment en secondes
- `label` : Classe/label du segment (entier, ex: 1, 2, 3, 4)
- `reliability` : Fiabilit√© de l'annotation (1-3, o√π 3 = tr√®s fiable)

**Note :** Le fichier `data/annotation.csv` est g√©n√©r√© automatiquement par `slicing.py`. Si vous ajoutez manuellement des fichiers audio dans `data/slices/`, vous devrez mettre √† jour `data/annotation.csv` manuellement.

#### √âtape 4 : R√©entra√Æner le Mod√®le

Une fois les nouvelles donn√©es ajout√©es :

```bash
python model_improved.py
```

Le mod√®le sera r√©entra√Æn√© avec toutes les donn√©es (anciennes + nouvelles).

### M√©thode 2 : Utiliser le Script d'Annotation

Le script `annotation.py` cr√©e le fichier `data/raw/annotations_raw.csv` √† partir de donn√©es brutes. Modifiez la variable `raw_data` dans le script pour ajouter vos propres annotations.

---

## ‚öôÔ∏è Param√®tres du Mod√®le

### Extraction de Caract√©ristiques

Le mod√®le extrait **304 caract√©ristiques** par fichier audio :

| Caract√©ristique | Nombre | Description |
|----------------|--------|-------------|
| **Mel-spectrogramme** | 256 | Moyenne (128) + √âcart-type (128) |
| **MFCC** | 26 | 13 coefficients avec moyenne et √©cart-type |
| **Chroma** | 12 | Caract√©ristiques harmoniques |
| **Spectral Contrast** | 7 | Contraste spectral |
| **Zero Crossing Rate** | 2 | Moyenne et √©cart-type |
| **Tempo** | 1 | Estimation du tempo (BPM) |
| **TOTAL** | **304** | |

**Param√®tres d'extraction :**
- Sample rate : 22050 Hz
- Mel bands : 128
- MFCC coefficients : 13

### Architecture du Mod√®le

```
Input (304 features)
  ‚Üì
Dense(512) + BatchNormalization + Dropout(0.5)
  ‚Üì
Dense(256) + BatchNormalization + Dropout(0.4)
  ‚Üì
Dense(128) + BatchNormalization + Dropout(0.3)
  ‚Üì
Dense(64) + BatchNormalization + Dropout(0.2)
  ‚Üì
Output (num_classes) + Softmax
```

**Hyperparam√®tres :**
- **Optimiseur** : Adam
- **Learning rate** : 0.0001 (avec decay)
- **Loss function** : Categorical crossentropy
- **Batch size** : 16
- **Epochs** : 200 (avec early stopping)
- **Early stopping patience** : 20 epochs
- **Reduce LR patience** : 10 epochs

### Augmentation de Donn√©es

Pour chaque √©chantillon d'entra√Ænement, le mod√®le cr√©e plusieurs versions augment√©es :
- **Bruit gaussien** : Ajout de bruit l√©ger (œÉ=0.005)
- **Time stretching** : Ralentissement (rate=0.9) et acc√©l√©ration (rate=1.1)
- **Pitch shifting** : Modification de la hauteur tonale (¬±2 demi-tons)

### Normalisation

- **StandardScaler** : Normalisation z-score (moyenne=0, √©cart-type=1)
- Le scaler est sauvegard√© dans `scaler.pkl` pour √™tre r√©utilis√© lors des pr√©dictions

---

## üìä Format des Donn√©es

### Fichier d'Annotations Brutes (`data/raw/annotations_raw.csv`)

Format des annotations brutes avec timestamps :

```csv
Start,End,Label,Reliability
00:09:34,00:10:12,1,3
00:11:30,00:11:43,2,3
```

### Fichier d'Annotations Principal (`data/annotation.csv`)

```csv
nfile,length,label,reliability
slice_001.wav,38,1,3
slice_002.wav,13,2,3
```

**Labels :**
- Les labels sont des entiers (1, 2, 3, 4, etc.)
- Le nombre de classes est d√©termin√© automatiquement
- **Important** : Chaque classe doit avoir au moins 2 √©chantillons pour permettre la stratification

**Reliability :**
- 1 : Faible fiabilit√©
- 2 : Fiabilit√© moyenne
- 3 : Haute fiabilit√©

### Fichier Audio

**Format support√© :**
- `.wav` (recommand√©)
- `.mp3`, `.flac`, `.m4a`, `.ogg`, `.aac` (via librosa)

**Recommandations :**
- Dur√©e des segments : 10-60 secondes (optimal : 20-40 secondes)
- Sample rate : Toute valeur (sera convertie √† 22050 Hz)
- Canaux : Mono ou st√©r√©o (sera converti en mono)

### Fichier de Pr√©dictions (`output/predictions_raw.csv`)

Format g√©n√©r√© par `predict_full_audio.py` :

```csv
Start,End,Label,Reliability
00:03:20,00:03:50,4,1
00:09:35,00:10:05,4,1
```

**Colonnes :**
- `Start` : Timestamp de d√©but (HH:MM:SS)
- `End` : Timestamp de fin (HH:MM:SS)
- `Label` : Classe pr√©dite
- `Reliability` : 1 (‚â•50%), 2 (‚â•60%), 3 (‚â•80% confiance)

---

## üìú Scripts Disponibles

### `model_improved.py`
**Entra√Ænement du mod√®le am√©lior√©**
- Extrait les caract√©ristiques
- Normalise les donn√©es
- Augmente les donn√©es
- Entra√Æne le mod√®le
- Sauvegarde le mod√®le et le scaler

### `predict_improved.py`
**Pr√©diction sur un fichier audio**
- Charge le mod√®le et le scaler
- Extrait les caract√©ristiques
- Fait la pr√©diction
- Affiche les r√©sultats

### `predict_full_audio.py`
**Analyse d'un fichier audio complet**
- D√©coupe le fichier en segments
- Pr√©dit chaque segment
- Fusionne les segments cons√©cutifs
- G√©n√®re un CSV avec les r√©sultats

### `main.py`
**Script principal avec menu interactif**
- Interface simple pour lancer toutes les √©tapes
- Usage : `python main.py` ou `python main.py [num√©ro]`

### `slicing.py`
**D√©coupage d'un fichier audio**
- D√©coupe un fichier audio en segments bas√©s sur des annotations
- G√©n√®re les fichiers dans `data/slices/`
- Cr√©e `data/annotation.csv` automatiquement

### `annotation.py`
**Cr√©ation du fichier d'annotations**
- Convertit des donn√©es brutes en format CSV

---

## üîç D√©pannage

### Erreur : "No librosa.feature attribute chroma"
**Solution :** Le script d√©tecte automatiquement les fonctions disponibles. Si chroma n'est pas disponible, des z√©ros seront utilis√©s √† la place.

### Erreur : "The least populated class has only 1 member"
**Solution :** Chaque classe doit avoir au moins 2 √©chantillons. Ajoutez plus de donn√©es pour les classes minoritaires.

### Erreur : "File not found"
**Solution :** V√©rifiez que :
- Les fichiers audio sont dans le dossier `data/slices/`
- Les noms dans `data/annotation.csv` correspondent exactement aux noms des fichiers
- Les chemins sont corrects

### Performance Faible
**Solutions possibles :**
1. **Ajouter plus de donn√©es** : Le mod√®le a besoin d'au moins 50-100 √©chantillons par classe pour de bonnes performances
2. **√âquilibrer les classes** : Les classes d√©s√©quilibr√©es peuvent causer des probl√®mes
3. **V√©rifier la qualit√© des annotations** : Des annotations incorrectes d√©gradent les performances
4. **Ajuster les hyperparam√®tres** : Modifier le learning rate, batch size, etc.

### Mod√®le qui Surapprend
**Le mod√®le inclut d√©j√† :**
- Dropout (0.2-0.5)
- BatchNormalization
- Early stopping
- Augmentation de donn√©es

**Si le surapprentissage persiste :**
- Ajoutez plus de donn√©es
- Augmentez le dropout
- R√©duisez la taille du mod√®le

---

## üìà Am√©liorations Futures

- [ ] Support pour les architectures CNN 2D (spectrogrammes complets)
- [ ] Support pour LSTM/BiLSTM (d√©pendances temporelles)
- [ ] Transfer learning avec mod√®les pr√©-entra√Æn√©s
- [ ] Interface web pour l'annotation
- [ ] Validation crois√©e k-fold
- [ ] Recherche d'hyperparam√®tres automatis√©e
- [ ] Support pour l'apprentissage continu (fine-tuning)

---

## üìù Notes Importantes

1. **Donn√©es limit√©es** : Avec seulement 27-29 √©chantillons, les performances seront limit√©es. Collectez plus de donn√©es pour de meilleurs r√©sultats.

2. **Classes d√©s√©quilibr√©es** : Si certaines classes ont beaucoup plus d'√©chantillons que d'autres, le mod√®le peut √™tre biais√©. Essayez d'√©quilibrer les classes.

3. **Qualit√© des annotations** : La qualit√© du mod√®le d√©pend directement de la qualit√© des annotations. V√©rifiez que les labels sont corrects.

4. **Normalisation** : Le scaler (`models/scaler.pkl`) doit √™tre utilis√© avec le m√™me mod√®le. Si vous r√©entra√Ænez le mod√®le, r√©g√©n√©rez le scaler.

5. **Compatibilit√©** : Le mod√®le sauvegard√© (`model_improved.h5`) est compatible avec TensorFlow 2.x.

---

## üìß Support

Pour toute question ou probl√®me, consultez :
- Le fichier `AMELIORATIONS.md` pour les d√©tails techniques des am√©liorations
- Les commentaires dans les scripts Python
- La documentation TensorFlow : https://www.tensorflow.org/
- La documentation librosa : https://librosa.org/

---

**Derni√®re mise √† jour :** D√©cembre 2025
